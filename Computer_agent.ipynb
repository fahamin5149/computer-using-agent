{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl/uG5sd6dO5GADywXXA6O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahamin5149/computer-using-agent/blob/main/Computer_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama_index llama-index-llms-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0_sWGpYZQLl",
        "outputId": "4ab0a6f0-f565-48d2-85ad-9329b3e377b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.6/250.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama-index-vector-stores-qdrant llama-index-readers-file llama-index-embeddings-fastembed\n",
        "!pip install -q youtube-transcript-api langchain_community tiktoken langchain-openai langchainhub chromadb langchain langchain-core langchain_google_genai llama_index qdrant-client sentence-transformers fastembed llama-index-llms-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RgECA44JbSsf",
        "outputId": "84142666-e0d5-49b1-80ba-456884ff59ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-vector-stores-qdrant\n",
            "  Downloading llama_index_vector_stores_qdrant-0.4.3-py3-none-any.whl.metadata (767 bytes)\n",
            "Requirement already satisfied: llama-index-readers-file in /usr/local/lib/python3.11/dist-packages (0.4.4)\n",
            "Collecting llama-index-embeddings-fastembed\n",
            "  Downloading llama_index_embeddings_fastembed-0.3.0-py3-none-any.whl.metadata (697 bytes)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-qdrant) (1.70.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.7 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-qdrant) (0.12.15)\n",
            "Collecting qdrant-client>=1.7.1 (from llama-index-vector-stores-qdrant)\n",
            "  Downloading qdrant_client-1.13.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file) (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file) (5.2.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file) (0.0.26)\n",
            "Collecting fastembed>=0.2.2 (from llama-index-embeddings-fastembed)\n",
            "  Downloading fastembed-0.5.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.11/dist-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (0.27.1)\n",
            "Collecting loguru<0.8.0,>=0.7.2 (from fastembed>=0.2.2->llama-index-embeddings-fastembed)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting mmh3<5.0.0,>=4.1.0 (from fastembed>=0.2.2->llama-index-embeddings-fastembed)\n",
            "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.26.4)\n",
            "Collecting onnxruntime!=1.20.0,>=1.17.0 (from fastembed>=0.2.2->llama-index-embeddings-fastembed)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting pillow<11.0.0,>=10.3.0 (from fastembed>=0.2.2->llama-index-embeddings-fastembed)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed>=0.2.2->llama-index-embeddings-fastembed)\n",
            "  Downloading py_rust_stemmers-0.1.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.11/dist-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (0.21.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.11/dist-packages (from fastembed>=0.2.2->llama-index-embeddings-fastembed) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.9.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.17.2)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant)\n",
            "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.18.3)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools>=1.41.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant)\n",
            "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (3.17.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed>=0.2.2->llama-index-embeddings-fastembed) (24.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2024.11.6)\n",
            "Collecting coloredlogs (from onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (25.1.24)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.31->fastembed>=0.2.2->llama-index-embeddings-fastembed) (3.4.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (3.26.1)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant)\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.7.1->llama-index-vector-stores-qdrant)\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.7->llama-index-vector-stores-qdrant) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed>=0.2.2->llama-index-embeddings-fastembed) (1.3.0)\n",
            "Downloading llama_index_vector_stores_qdrant-0.4.3-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_embeddings_fastembed-0.3.0-py3-none-any.whl (2.7 kB)\n",
            "Downloading fastembed-0.5.1-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qdrant_client-1.13.2-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading py_rust_stemmers-0.1.3-cp311-cp311-manylinux_2_28_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: py-rust-stemmers, mmh3, protobuf, portalocker, pillow, loguru, hyperframe, humanfriendly, hpack, h2, grpcio-tools, coloredlogs, onnxruntime, qdrant-client, fastembed, llama-index-vector-stores-qdrant, llama-index-embeddings-fastembed\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "Successfully installed coloredlogs-15.0.1 fastembed-0.5.1 grpcio-tools-1.70.0 h2-4.2.0 hpack-4.1.0 humanfriendly-10.0 hyperframe-6.1.0 llama-index-embeddings-fastembed-0.3.0 llama-index-vector-stores-qdrant-0.4.3 loguru-0.7.3 mmh3-4.1.0 onnxruntime-1.20.1 pillow-10.4.0 portalocker-2.10.1 protobuf-5.29.3 py-rust-stemmers-0.1.3 qdrant-client-1.13.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "b67f82b070cc4c7d8bab210deb0144a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.core import Document\n",
        "import uuid\n",
        "from llama_index.core.text_splitter import SentenceSplitter\n",
        "import logging\n",
        "import sys\n",
        "import os\n",
        "import qdrant_client\n",
        "from IPython.display import Markdown, display\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
        "from llama_index.core import Settings\n"
      ],
      "metadata": {
        "id": "HMSL1vqxd3Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up LLM"
      ],
      "metadata": {
        "id": "JHmfYX1BZLtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kx6BwlAdyBP",
        "outputId": "8eb12351-a539-494b-fe36-f61ce62c12df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aisXK2ECYp8g"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "client = Groq(\n",
        "    api_key=userdata.get('groq_api'),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Generate a numbered, ordered list of technical topics I should learn if I want to work on LLM\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"deepseek-r1-distill-llama-70b\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnQG0swEcQmU",
        "outputId": "485f2017-a79b-4b27-9d02-46bd45ced2bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, so I want to work on Large Language Models (LLMs), but I'm not really sure where to start. I know a bit about programming, but I'm not super confident in all the areas needed for this. Let me try to break it down.\n",
            "\n",
            "First, I remember that LLMs are a type of machine learning model, specifically in the realm of natural language processing. So, I probably need to understand the basics of machine learning. I've heard terms like supervised learning, unsupervised learning, and reinforcement learning. I think supervised learning is where the model is trained on labeled data, which makes sense for something like a language model where you have input and expected output.\n",
            "\n",
            "Then there's deep learning. I know that's a subset of machine learning involving neural networks. I've heard about CNNs and RNNs, but I'm not exactly sure how they apply to LLMs. Wait, LLMs use transformers, right? So maybe I should focus more on transformers and attention mechanisms. I remember that transformers were introduced in a paper called \"Attention is All You Need.\" I should probably read that or at least understand the key concepts from it.\n",
            "\n",
            "Natural Language Processing (NLP) is obviously crucial here. I've used some libraries like NLTK and spaCy before, but I'm not sure how they fit into building an LLM. Maybe I need to understand tokenization, stemming, lemmatization, and part-of-speech tagging better. Oh, and word embeddings! I've heard of Word2Vec and GloVe, but I think newer models use subword tokenization like BPE or SentencePiece. That makes sense because it handles rare words better.\n",
            "\n",
            "Moving on to the architecture of LLMs. I know they're based on transformers, which use self-attention. I should probably dive deeper into how the encoder and decoder work, especially since some models are encoder-only or decoder-only. Also, pre-training and fine-tuning are important concepts. Pre-training on a large corpus to learn language patterns and then fine-tuning for specific tasks. I think that's how models like BERT and GPT are trained.\n",
            "\n",
            "Optimization techniques must be important too. I've heard of Adam optimizer and SGD, but I'm not sure about learning rate scheduling. Maybe learning rate warm-up is a thing? And normalization techniques like LayerNorm. I remember that in transformers, LayerNorm is used after each sub-layer.\n",
            "\n",
            "Hardware and software are another area. I know that training large models requires a lot of computational power. So, understanding GPUs and TPUs is probably necessary. I've used TensorFlow before, but PyTorch seems more popular now. Maybe I should get comfortable with PyTorch. Also, distributed training across multiple GPUs or machines must be a thing for large models. I've heard about model parallelism and data parallelism but don't fully understand the differences yet.\n",
            "\n",
            "Evaluation metrics for LLMs... I know about perplexity, which measures how well the model predicts a test set. Then there's BLEU and ROUGE for generation tasks, but I'm not sure how they work exactly. Also, understanding bias and fairness in models is important because LLMs can reflect biases in their training data.\n",
            "\n",
            "Advanced topics like few-shot and zero-shot learning sound interesting. I think few-shot learning is when the model can learn from a few examples, which is useful for tasks with limited data. Zero-shot is when it can handle tasks it wasn't explicitly trained on. Transfer learning is probably related, where a model is pre-trained on one task and adapted to another.\n",
            "\n",
            "Efficiency and scalability must be a big deal for large models. I've heard about model compression and pruning to reduce the model size without losing much performance. Quantization is another term I've come across, which involves reducing the precision of model weights to save memory. Also, efficient attention mechanisms might be important because the standard attention is O(n²), which isn't great for very long sequences.\n",
            "\n",
            "Specialized models like multimodal models that handle text and images, or models for specific domains like legal or medical text. I'm not sure how different those are from general LLMs, but they probably require additional training data or fine-tuning.\n",
            "\n",
            "Ethical considerations are crucial. I know that LLMs can generate harmful content or reinforce biases. So, understanding how to mitigate these issues is important. Also, environmental impact because training large models uses a lot of energy.\n",
            "\n",
            "Staying updated with the latest research is something I need to do. Following arXiv, attending conferences, and joining communities will help me keep up with new developments. Practical experience is key too, so I should try to work on projects, maybe contribute to open-source LLM projects.\n",
            "\n",
            "Wait, did I miss anything? Maybe the actual implementation details, like how to set up a training pipeline, handle distributed training, or use specific libraries for LLMs. Also, maybe understanding the math behind transformers, like the attention mechanism's mathematical formulation. I think linear algebra and calculus are important here, so brushing up on those might help.\n",
            "\n",
            "I'm a bit overwhelmed, but breaking it down into these areas makes it manageable. I should start with the basics, make sure I understand each concept before moving on, and practice by working on small projects or contributing to existing ones. Maybe take some online courses or read books on NLP and deep learning to fill in the gaps.\n",
            "</think>\n",
            "\n",
            "To effectively work on Large Language Models (LLMs), it's essential to approach the topic systematically. Here's a structured plan based on the thought process:\n",
            "\n",
            "### 1. **Foundational Knowledge**\n",
            "   - **Machine Learning Basics**: Understand supervised, unsupervised, and reinforcement learning.\n",
            "   - **Deep Learning**: Focus on neural networks, particularly transformers and attention mechanisms. Read the \"Attention is All You Need\" paper.\n",
            "\n",
            "### 2. **Natural Language Processing (NLP)**\n",
            "   - **Core Concepts**: Tokenization, stemming, lemmatization, part-of-speech tagging, and word embeddings (Word2Vec, GloVe).\n",
            "   - **Subword Tokenization**: Learn BPE and SentencePiece for handling rare words.\n",
            "\n",
            "### 3. **LLM Architecture**\n",
            "   - **Transformers**: Study encoder-decoder structures, self-attention, and multi-head attention.\n",
            "   - **Training Strategies**: Pre-training on large corpora and fine-tuning for specific tasks.\n",
            "\n",
            "### 4. **Optimization Techniques**\n",
            "   - **Algorithms**: Adam optimizer, SGD, and learning rate scheduling.\n",
            "   - **Normalization**: LayerNorm in transformers.\n",
            "\n",
            "### 5. **Hardware and Software**\n",
            "   - **Compute**: Use of GPUs, TPUs, and distributed training (model/data parallelism).\n",
            "   - **Frameworks**: Proficiency in PyTorch and TensorFlow.\n",
            "\n",
            "### 6. **Evaluation Metrics**\n",
            "   - **Performance**: Perplexity, BLEU, ROUGE.\n",
            "   - **Ethics**: Bias mitigation and fairness in models.\n",
            "\n",
            "### 7. **Advanced Topics**\n",
            "   - **Learning Paradigms**: Few-shot, zero-shot learning, and transfer learning.\n",
            "   - **Efficiency**: Model compression, pruning, quantization, and efficient attention mechanisms.\n",
            "\n",
            "### 8. **Specialized Models**\n",
            "   - **Multimodal and Domain-Specific Models**: Handling text and images, or specific domains like legal or medical.\n",
            "\n",
            "### 9. **Ethical Considerations**\n",
            "   - **Safety and Environment**: Addressing harmful content and energy consumption.\n",
            "\n",
            "### 10. **Continuous Learning**\n",
            "   - **Research**: Follow arXiv, conferences, and communities.\n",
            "   - **Practice**: Engage in projects and open-source contributions.\n",
            "\n",
            "### 11. **Mathematical Foundations**\n",
            "   - **Linear Algebra and Calculus**: Essential for understanding model mechanics.\n",
            "\n",
            "### 12. **Implementation Details**\n",
            "   - ** Pipelines and Tools**: Setup for training, distributed environments, and specific libraries.\n",
            "\n",
            "### Action Plan\n",
            "- Start with basics, ensuring each concept is understood before moving on.\n",
            "- Supplement learning with courses, books, and practical projects.\n",
            "- Contribute to open-source projects to gain hands-on experience.\n",
            "\n",
            "By following this structured approach, you can build a comprehensive understanding and practical skills needed to work on LLMs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Hello! You are an assistant who will only reply in Roman urdu language\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Kia haal hai? Main aapki kaise madad kar sakta hoon?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Create a well-organized routine for me\"}\n",
        "    ],\n",
        "    model=\"deepseek-r1-distill-llama-70b\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O62FXc8OcdDh",
        "outputId": "4413b02b-aab5-4fae-a5f1-fd8a1088ee74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Alright, the user has asked me to create a well-organized routine for them. Since they specified that I should reply in Roman Urdu, I need to make sure my response is in that format. \n",
            "\n",
            "First, I should consider the typical structure of a daily routine. It usually starts early in the morning, so I'll begin with waking up and then include activities like exercise, breakfast, work or study, breaks, lunch, more work, leisure time, dinner, relaxation, and bedtime.\n",
            "\n",
            "I should break the day into segments with specific timings to make it clear and easy to follow. Each activity should be in Roman Urdu, so I'll translate each part accordingly. I'll also include notes at the end to emphasize the importance of sticking to the routine and adjusting it based on individual needs.\n",
            "\n",
            "I need to ensure that the timings are realistic and allow for a balanced day. Including breaks and leisure time is important for overall well-being. Also, ending the day with a consistent bedtime helps in maintaining a healthy sleep schedule.\n",
            "\n",
            "I'll present the routine in a numbered list format for clarity. Each point will have the time in bold, followed by the activity in Roman Urdu. I'll make sure the translations are accurate and easy to understand.\n",
            "\n",
            "Finally, I'll add a friendly note encouraging the user to adjust the routine as needed and wish them the best in their new schedule.\n",
            "</think>\n",
            "\n",
            "Bilkul! Yeh raha aapka well-organized daily routine:\n",
            "\n",
            "1. **6:00 AM - Uthna aur morning routine (Brushing, washing face, etc.)**\n",
            "2. **6:30 AM - Exercise (Yoga, jogging, ya gym)**  \n",
            "3. **7:15 AM - Breakfast karna**\n",
            "4. **8:00 AM - Work ya studies shuru karna**\n",
            "5. **12:00 PM - Lunch break**\n",
            "6. **1:00 PM - Work ya studies continue**\n",
            "7. **4:00 PM - Chai break aur thoda rest**\n",
            "8. **4:30 PM - Work ya studies continue**\n",
            "9. **6:00 PM - Dinner karna**\n",
            "10. **7:00 PM - Family ya friends ke saath time spend karna**\n",
            "11. **8:00 PM - Relaxation (Reading, TV, ya hobbies)**\n",
            "12. **9:30 PM - Bedtime routine (Brushing, changing clothes, etc.)**\n",
            "13. **10:00 PM - Sleep**\n",
            "\n",
            "Is routine ko follow karte hue aapka din organize ho sakta hai. Agar aapko koi changes chahiye, toh apni zaroorat ke hisab se adjust kar sakte hain. Best of luck!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Max Token"
      ],
      "metadata": {
        "id": "rjdNaqM_i8Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Generate a numbered, ordered list of technical topics I should learn if I want to work on LLM\",\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=100,\n",
        "    model=\"deepseek-r1-distill-llama-70b\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtTwFpy9i66T",
        "outputId": "cd3ba059-e49c-4570-a1fe-910d5d8e6961"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, so I want to work on Large Language Models (LLMs), but I'm not exactly sure where to start. I remember reading that LLMs are a big part of AI these days, used for things like chatbots, translation, and text generation. But the actual technical stuff behind them is a bit fuzzy to me. I need to figure out what I should learn to get into this field.\n",
            "\n",
            "First, I think I should understand the basics of machine learning because LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion.choices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJHqwPlqflVJ",
        "outputId": "e26f4c8a-b9a1-4299-82ea-4f7a9a094d0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"<think>\\nOkay, so I want to work on Large Language Models (LLMs), but I'm not exactly sure where to start. I remember reading that LLMs are a big part of AI these days, used for things like chatbots, translation, and text generation. But the actual technical stuff behind them is a bit fuzzy to me. I need to figure out what I should learn to get into this field.\\n\\nFirst, I think I should understand the basics of machine learning because LLM\", role='assistant', function_call=None, reasoning=None, tool_calls=None))]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Temperature\n",
        "Higher temperature means more creativity"
      ],
      "metadata": {
        "id": "kSsrjha-jPmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Generate a numbered, ordered list of technical topics I should learn if I want to work on LLM\",\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    model=\"deepseek-r1-distill-llama-70b\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtD18EiqjF8F",
        "outputId": "114c0336-61c7-45cb-ce39-ade38ab53ba5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, so I'm trying to figure out what technical topics I should learn to work on Large Language Models (LLMs). I'm pretty new to this field, so I need to start from the basics and build up. Let me think through this step by step.\n",
            "\n",
            "First, I know that LLMs are a type of artificial intelligence, so I should probably start with the foundations of AI and machine learning. I've heard terms like supervised learning, unsupervised learning, and reinforcement learning. I'm not entirely sure what each entails, but I think they are different ways machines can learn from data. I should look into each of these to understand how they apply to LLMs.\n",
            "\n",
            "Next, neural networks seem important. I remember hearing about perceptrons and how they form the building blocks of neural networks. Maybe I should learn about how these networks operate, including forward and backward propagation. Activation functions like ReLU and sigmoid must be important too. I've heard about backpropagation and gradient descent, which are methods for training these networks, so I need to understand those.\n",
            "\n",
            "Deep learning is a subset of machine learning, so I guess I should dive deeper into that. I've heard of CNNs and RNNs. CNNs are used for images, right? But how do they apply to LLMs? Maybe for processing visual data alongside text. RNNs, on the other hand, are for sequences, like text or time series data. Since LLMs deal with text sequences, understanding RNNs, especially LSTMs and GRUs, which handle long-term dependencies, seems crucial.\n",
            "\n",
            "Transformers are a big deal in LLMs. The Transformer architecture was introduced in a paper called \"Attention Is All You Need.\" I should definitely read that. The key components are self-attention mechanisms, positional encoding, and multi-head attention. I need to understand how these allow models to process sequences in parallel and handle long-range dependencies better than RNNs.\n",
            "\n",
            "Pretrained models like BERT, RoBERTa, and GPT-3 are widely used, so learning about their architectures and how they're trained is important. Each has its own approach to pretraining, whether it's masked language modeling or next sentence prediction. Fine-tuning these models for specific tasks must be a key skill too.\n",
            "\n",
            "Now, moving into more specific areas, the transformer architecture in depth would help. Understanding how the encoder and decoder work, the role of positional encodings, and how multi-head attention is implemented is essential. I should also explore variants like BERT and RoBERTa to see how they differ and why certain architectures are chosen for specific tasks.\n",
            "\n",
            "Natural Language Processing (NLP) is obviously central to LLMs. I need to cover the basics like text preprocessing, tokenization, and word embeddings. Understanding both traditional and modern techniques will give me a solid foundation. Then, I can move on to tasks like text classification, sentiment analysis, machine translation, and summarization, which are common applications of LLMs.\n",
            "\n",
            "Language model training and evaluation are critical. I should learn about the different training objectives, such as masked language modeling and next sentence prediction, and how models are evaluated using metrics like perplexity and BLEU. The challenges in training these models, such as computational requirements and handling large datasets, must be considered as well.\n",
            "\n",
            "Optimization techniques for training LLMs are another area. I'm familiar with SGD and Adam, but I need to understand how they're applied in large-scale training. Distributed training methods, mixed-precision training, and strategies to prevent overfitting like dropout and weight decay are important for efficient and effective model training.\n",
            "\n",
            "Attention mechanisms are a cornerstone of transformers. I should delve deeper into scaled dot-product attention and multi-head attention to understand how they capture different aspects of data. Exploring attention variants and their applications in various tasks will help me appreciate the flexibility of these models.\n",
            "\n",
            "Advanced topics like few-shot and zero-shot learning are interesting because they show how LLMs can adapt to new tasks with minimal examples. I should also look into prompt engineering, which is about crafting effective prompts to guide the model's output. Reinforcement learning from human feedback (RLHF) is another area where models are fine-tuned based on human preferences, which seems like a powerful technique.\n",
            "\n",
            "Explainability and interpretability of LLMs are important, especially for understanding how these complex models make decisions. Techniques like LIME and SHAP can help in making the model's outputs more transparent. Ethical considerations, such as bias and fairness, are crucial to ensure that models don't perpetuate harmful stereotypes or biases present in the training data.\n",
            "\n",
            "Efficiency and scalability are key when dealing with large models. I need to learn about model compression techniques like pruning and quantization to make models more efficient. Efficient attention mechanisms can help reduce computational costs, and strategies for scaling models up or down depending on the task are essential.\n",
            "\n",
            "Applications of LLMs are vast. I should explore NLP tasks, multimodal applications like processing text and images together, and generative applications such as text and code generation. Each application might require different fine-tuning approaches and model architectures.\n",
            "\n",
            "Staying updated with the latest research and advancements is crucial in this fast-paced field. Reading papers from top conferences and following blogs can keep me informed. Engaging with communities through forums and attending meetups can provide networking opportunities and insights from practitioners.\n",
            "\n",
            "Finally, practical experience is indispensable. Building small-scale LLMs or fine-tuning existing models can provide hands-on learning. Using popular libraries and frameworks will help me implement these models and experiment with different techniques.\n",
            "\n",
            "Putting it all together, I think the list should start with foundational AI and ML, move through neural networks and deep learning, into NLP basics, then dive into LLM specifics like transformers and pretraining, followed by advanced topics, efficiency, applications, and finally practical experience and community engagement. This structured approach should give me a comprehensive understanding needed to work on LLMs.\n",
            "</think>\n",
            "\n",
            "To work effectively on Large Language Models (LLMs), it's essential to follow a structured learning approach that covers foundational concepts, progresses through intermediate topics, and culminates in advanced and practical applications. Here's an organized and comprehensive list of technical topics to guide your learning journey:\n",
            "\n",
            "### 1. **Foundations of AI and Machine Learning**\n",
            "   - **Supervised, Unsupervised, and Reinforcement Learning**: Understand the different paradigms of machine learning.\n",
            "   - **Neural Networks Basics**: Study perceptrons, activation functions (ReLU, Sigmoid), forward/backward propagation, and backpropagation.\n",
            "\n",
            "### 2. **Deep Learning Fundamentals**\n",
            "   - **CNNs and RNNs**: Learn about Convolutional Neural Networks for image processing and Recurrent Neural Networks for sequential data.\n",
            "   - **LSTMs and GRUs**: Focus on handling long-term dependencies in text sequences.\n",
            "\n",
            "### 3. **Transformer Architecture**\n",
            "   - **Transformers and Self-Attention**: Delve into the \"Attention Is All You Need\" paper, self-attention mechanisms, and multi-head attention.\n",
            "   - **Pretrained Models**: Explore BERT, RoBERTa, and GPT-3, including their architectures and fine-tuning methods.\n",
            "\n",
            "### 4. **Natural Language Processing (NLP)**\n",
            "   - **Text Preprocessing and Tokenization**: Understand techniques like tokenization and word embeddings.\n",
            "   - **NLP Tasks**: Study text classification, sentiment analysis, machine translation, and summarization.\n",
            "\n",
            "### 5. **Language Model Training and Evaluation**\n",
            "   - **Training Objectives and Evaluation Metrics**: Learn about masked language modeling, perplexity, and BLEU.\n",
            "   - **Training Challenges**: Address computational needs, large datasets, and optimization techniques.\n",
            "\n",
            "### 6. **Optimization Techniques**\n",
            "   - **SGD, Adam, and Distributed Training**: Understand optimization methods and distributed training for large models.\n",
            "   - **Regularization Techniques**: Learn dropout and weight decay to prevent overfitting.\n",
            "\n",
            "### 7. **Attention Mechanisms**\n",
            "   - **Scaled Dot-Product and Multi-Head Attention**: Explore their applications and variants.\n",
            "\n",
            "### 8. **Advanced Topics**\n",
            "   - **Few-Shot and Zero-Shot Learning**: Learn how LLMs adapt to new tasks with minimal examples.\n",
            "   - **Prompt Engineering and RLHF**: Craft effective prompts and fine-tune models using human feedback.\n",
            "\n",
            "### 9. **Explainability and Ethics**\n",
            "   - **Interpretability Techniques**: Use LIME and SHAP for model transparency.\n",
            "   - **Bias and Fairness**: Address ethical considerations in model training and deployment.\n",
            "\n",
            "### 10. **Efficiency and Scalability**\n",
            "   - **Model Compression and Attention Mechanisms**: Optimize models with pruning, quantization, and efficient attention.\n",
            "   - **Scaling Strategies**: Adjust models for different tasks and computational constraints.\n",
            "\n",
            "### 11. **Applications of LLMs**\n",
            "   - **NLP and Multimodal Tasks**: Explore text, image, and generative applications.\n",
            "   - **Generative Applications**: Focus on text and code generation.\n",
            "\n",
            "### 12. **Community Engagement and Research**\n",
            "   - **Stay Updated**: Follow research papers, blogs, and conferences.\n",
            "   - **Engage with Communities**: Participate in forums and meetups for networking and insights.\n",
            "\n",
            "### 13. **Practical Experience**\n",
            "   - **Hands-On Projects**: Build small-scale LLMs or fine-tune existing models.\n",
            "   - **Tools and Frameworks**: Use libraries like TensorFlow or PyTorch for implementation.\n",
            "\n",
            "By systematically learning and applying these topics, you'll gain a comprehensive understanding of LLMs, from foundational concepts to advanced applications, enabling you to contribute effectively in this dynamic field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vision model"
      ],
      "metadata": {
        "id": "TGPr-eWA0gcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import base64\n",
        "\n",
        "\n",
        "# Function to encode the image\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# Path to your image\n",
        "image_path = \"sf.png\"\n",
        "\n",
        "# Getting the base64 string\n",
        "base64_image = encode_image(image_path)\n",
        "\n",
        "client = Groq(\n",
        "    api_key=userdata.get('groq_api'),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.2-90b-vision-preview\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt8mUBDkoyXs",
        "outputId": "ada157e2-eb04-494d-add7-f8d89d43b33c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image depicts a collection of takeout containers on a wooden table. The containers are arranged in two stacks, with one stack featuring rectangular plastic containers and the other consisting of octagonal white cardboard containers. The rectangular containers have clear lids, while the octagonal containers have lids that are folded back to reveal their contents.\n",
            "\n",
            "In the background, there are several utensils and chairs visible. The utensils appear to be chopsticks or skewers, which suggests that the food inside the containers may be Asian-inspired cuisine. The chairs are dark-colored and have a simple design, adding to the overall casual atmosphere of the scene.\n",
            "\n",
            "Overall, the image presents a cozy and inviting setting, with the takeout containers and utensils arranged neatly on the table. The use of natural materials such as wood and the presence of chopsticks or skewers suggest a warm and intimate dining experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your image\n",
        "image_path = \"plant.png\"\n",
        "\n",
        "# Getting the base64 string\n",
        "base64_image = encode_image(image_path)\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"What species is this?\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.2-90b-vision-preview\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyR-OPtx3BdD",
        "outputId": "a109b609-634b-45f0-8923-6bd0e1177c39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a pitcher plant, specifically a Nepenthes species. The pitcher plant is a type of carnivorous plant that obtains essential nutrients by capturing and digesting insects and other small organisms. The plant's modified leaves form a deep, slippery cup or pitcher that fills with digestive fluids, trapping prey that falls into it. The plant's unique adaptation allows it to thrive in nutrient-poor soil by supplementing its nutrient intake through carnivory.\n",
            "\n",
            "Nepenthes is a genus of pitcher plants native to tropical regions of Asia, Australia, and Africa. They are known for their striking, colorful pitchers and their ability to capture a wide range of prey, from flies and spiders to even small vertebrates like frogs and lizards. Some species of Nepenthes have evolved to mimic flowers or fruit to attract prey, while others use scent or visual cues to lure in potential meals.\n",
            "\n",
            "Pitcher plants, including Nepenthes species, are popular among botanists and enthusiasts due to their unique biology and diversity. They are also important components of their ecosystems, providing habitat and food for various animals. However, many pitcher plant species are threatened by habitat loss and degradation, highlighting the need for conservation efforts to protect these fascinating plants and their habitats.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    image_url=base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "    return {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\n",
        "              \"url\": f\"data:image/jpeg;base64,{image_url}\",\n",
        "              },\n",
        "            }"
      ],
      "metadata": {
        "id": "of1W954H58fH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your image\n",
        "image_path = \"invoice.png\"\n",
        "\n",
        "# Getting the base64 string\n",
        "base64_image = encode_image(image_path)\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\":\n",
        "                 \"\"\"\n",
        "                Generate a JSON object representing the contents\n",
        "                of this invoice.  It should include all dates,\n",
        "                dollar amounts, and addresses.\n",
        "                Only respond with the JSON itself.\n",
        "                 \"\"\"\n",
        "\n",
        "                 },\n",
        "                encode_image(image_path),\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.2-90b-vision-preview\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldjzRNPz34vT",
        "outputId": "041ba1e3-67d8-4305-b19d-c1b916ba1504"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```\n",
            "{\n",
            "    \"invoice_number\": \"INV-2024-0042\",\n",
            "    \"date\": \"March 17, 2025\",\n",
            "    \"due_date\": \"April 16, 2025\",\n",
            "    \"bill_to\": {\n",
            "        \"name\": \"ACME CORPORATION\",\n",
            "        \"address\": \"789 Market Street, Suite 500, Los Angeles, CA 90015\"\n",
            "    },\n",
            "    \"description\": {\n",
            "        \"Enterprise Software License\": {\n",
            "            \"quantity\": 1,\n",
            "            \"unit_price\": 5000.00,\n",
            "            \"amount\": 5000.00\n",
            "        },\n",
            "        \"Implementation Services\": {\n",
            "            \"quantity\": 40,\n",
            "            \"unit_price\": 150.00,\n",
            "            \"amount\": 6000.00\n",
            "        },\n",
            "        \"Premium Support Plan (Annual)\": {\n",
            "            \"quantity\": 1,\n",
            "            \"unit_price\": 2500.00,\n",
            "            \"amount\": 2500.00\n",
            "        }\n",
            "    },\n",
            "    \"sub_total\": 13500.00,\n",
            "    \"tax\": 1147.50,\n",
            "    \"total\": 14647.50\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"How does open source companies work\"\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.2-90b-vision-preview\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRv4lwpN1BrC",
        "outputId": "8cc47aba-aba8-4add-d96f-3fadefafafca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Open-source companies operate on a unique business model that is centered around the concept of open-source software (OSS). Here's a general overview of how they work:\n",
            "\n",
            "**Key characteristics:**\n",
            "\n",
            "1. **Free and open access**: Open-source companies provide access to their software codebase, allowing users to view, modify, and distribute it freely.\n",
            "2. **Community-driven**: Open-source companies often rely on a community of developers, contributors, and users to participate in the development, testing, and maintenance of the software.\n",
            "3. **Licensing**: Open-source companies use licenses that permit users to modify and distribute the software, such as the GNU General Public License (GPL) or the Apache License.\n",
            "\n",
            "**Revenue streams:**\n",
            "\n",
            "While open-source software is free to use, open-source companies can generate revenue through various means:\n",
            "\n",
            "1. **Support and services**: Offer support, consulting, and training services to help users implement and customize the software.\n",
            "2. **Subscription-based models**: Provide premium features, updates, or support to users who pay a subscription fee.\n",
            "3. **Enterprise licensing**: Sell proprietary versions of the software or customized solutions to large enterprises.\n",
            "4. **Donations**: Accept donations from users or organizations that benefit from the open-source software.\n",
            "5. **Advertising and sponsorships**: Display ads or partner with sponsors to support the development of the software.\n",
            "\n",
            "**Examples of open-source companies:**\n",
            "\n",
            "1. **Red Hat**: Known for its enterprise Linux distribution, Red Hat generates revenue through subscriptions and support services.\n",
            "2. **Canonical**: The company behind Ubuntu, Canonical offers support, consulting, and training services to users.\n",
            "3. **MySQL**: MySQL, now owned by Oracle, generates revenue through sales of enterprise software and support services.\n",
            "4. **GitLab**: A platform for version control and collaboration, GitLab offers a free, open-source version and a paid, premium version with additional features.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "1. **Sustainability**: Open-source companies face the challenge of sustaining their business model, as the software is free to use.\n",
            "2. **Competing with proprietary solutions**: Open-source companies must compete with proprietary software vendors that have more resources and established customer bases.\n",
            "3. **Balancing community and commercial interests**: Open-source companies must balance the needs of their community with their commercial goals.\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "1. **Innovation**: Open-source companies can foster innovation and community-driven development.\n",
            "2. **Cost savings**: Open-source software can provide cost savings for users, as it is often free to use and modify.\n",
            "3. **Flexibility**: Open-source companies can offer flexible solutions that meet the needs of a wide range of users.\n",
            "\n",
            "In summary, open-source companies operate by providing free and open access to their software, relying on community contributions and support, and generating revenue through various means, such as support services, subscription-based models, and enterprise licensing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using stream which will speed up the call to first token"
      ],
      "metadata": {
        "id": "ozkYic2W74_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"How does open source companies work\"\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.2-90b-vision-preview\",\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for chunk in chat_completion:\n",
        "    if chunk.choices and chunk.choices[0].delta.content:\n",
        "        print(chunk.choices[0].delta.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWblRkDY1x_i",
        "outputId": "92739cc0-d719-4008-f0fe-1913e8a4bab0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Open-source companies are organizations that develop and maintain software, systems, or products using an open-source model. This model is characterized by the following key aspects:\n",
            "\n",
            "1. **Free availability of source code**: The source code of the software or system is made freely available to anyone, allowing them to use, modify, and distribute it.\n",
            "2. **Open licensing**: The software or system is licensed under an open-source license, which permits users to modify and distribute the software.\n",
            "3. **Community involvement**: Open-source companies often rely on a community of contributors, including developers, testers, and users, to help develop and maintain the software.\n",
            "\n",
            "Here's how open-source companies typically operate:\n",
            "\n",
            "**Business models**:\n",
            "\n",
            "1. **Support and services**: Open-source companies offer support, consulting, and training services to users of their software.\n",
            "2. **Licensing fees**: Some open-source companies charge fees for commercial use of their software, or for customized versions of the software.\n",
            "3. **Advertising and sponsorships**: Some open-source companies generate revenue through advertising, sponsorships, or affiliate programs.\n",
            "4. **Selling proprietary products**: Some open-source companies also sell proprietary products that complement their open-source offerings.\n",
            "\n",
            "**Community engagement**:\n",
            "\n",
            "1. **Contributor engagement**: Open-source companies encourage and engage with contributors, including developers, testers, and users, to ensure that the software is being developed and maintained by a diverse community.\n",
            "2. **Community feedback**: Open-source companies actively solicit feedback and input from the community to ensure that the software meets the needs of its users.\n",
            "3. **Collaboration**: Open-source companies collaborate with other open-source projects and companies to advance the overall ecosystem.\n",
            "\n",
            "**Revenue streams**:\n",
            "\n",
            "1. **Subscription-based models**: Some open-source companies offer subscription-based models that provide access to premium features, support, or updates.\n",
            "2. **Enterprise licenses**: Open-source companies sell licenses to large enterprises, often including custom support and consulting services.\n",
            "3. **Hardware sales**: Some open-source companies sell hardware that is specifically designed to work with their software.\n",
            "\n",
            "**Examples of open-source companies**:\n",
            "\n",
            "1. **Red Hat**: A leading provider of open-source software solutions, known for their Linux distributions and middleware platforms.\n",
            "2. **Canonical**: A UK-based company that develops and maintains the Ubuntu Linux distribution, and offers a range of services, including support and consulting.\n",
            "3. **MySQL (now part of Oracle)**: An open-source database management system that was acquired by Oracle in 2009.\n",
            "4. **GitLab**: A platform for version control and continuous integration that is free and open-source, with optional paid features.\n",
            "5. **Mozilla**: A non-profit organization that develops and maintains the Firefox web browser, as well as other open-source projects.\n",
            "\n",
            "**Challenges**:\n",
            "\n",
            "1. **Monetization**: Open-source companies need to navigate the challenge of generating revenue from free or low-cost products.\n",
            "2. **Competition**: Open-source companies face competition from proprietary software vendors, as well as from other open-source vendors.\n",
            "3. **Maintaining community engagement**: Open-source companies need to invest time and resources in engaging with their communities and keeping them involved in the development process.\n",
            "\n",
            "**Benefits**:\n",
            "\n",
            "1. **Community-driven innovation**: Open-source companies can leverage the collective creativity and ingenuity of a global community to drive innovation.\n",
            "2. **Transparency**: Open-source companies often operate with greater transparency, as their code and development processes are open to scrutiny.\n",
            "3. **Flexibility**: Open-source companies can offer flexible licensing models and customization options that are not always available with proprietary software.\n",
            "\n",
            "In summary, open-source companies rely on a community-driven development model, with revenue streams generated through support, services, licensing fees, and advertising. While there are challenges to be addressed, open-source companies can leverage the power of community engagement and innovation to drive growth and success."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enterprice prompt"
      ],
      "metadata": {
        "id": "jpfZdFItGe5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enterprise_prompt = \"\"\"\n",
        "Analyze the following customer service call transcript and generate a JSON summary of the interaction:\n",
        "\n",
        "<transcript>\n",
        "[INSERT CALL TRANSCRIPT HERE]\n",
        "</transcript>\n",
        "\n",
        "Instructions:\n",
        "<instructions>\n",
        "1. Read the transcript carefully.\n",
        "2. Analyze the transcript, focusing on the main issue, resolution, and any follow-up required.\n",
        "3. Generate a JSON object summarizing the key aspects of the interaction according to the specified structure.\n",
        "\n",
        "Important guidelines:\n",
        "- Confidentiality: Omit all specific customer data like names, phone numbers, and email addresses.\n",
        "- Character limit: Restrict each text field to a maximum of 100 characters.\n",
        "- Maintain a professional tone in your summary.\n",
        "\n",
        "Output format:\n",
        "Generate a JSON object with the following structure:\n",
        "<json>\n",
        "{\n",
        "  \"summary\": {\n",
        "    \"customerIssue\": \"Brief description of the main problem or reason for the call\",\n",
        "    \"resolution\": \"How the issue was addressed or resolved, if applicable\",\n",
        "    \"followUpRequired\": true/false,\n",
        "    \"followUpDetails\": \"Description of any necessary follow-up actions, or null if none required\"\n",
        "  },\n",
        "  \"status\": \"COMPLETE\",\n",
        "  \"ambiguities\": [\"List of any unclear or vague points in the conversation, or an empty array if none\"]\n",
        "}\n",
        "</json>\n",
        "\n",
        "Insufficient data criteria:\n",
        "   If any of these conditions are met:\n",
        "   a) The transcript has fewer than 5 total exchanges\n",
        "   b) The customer's issue is unclear\n",
        "   c) The call is garbled, incomplete, or is hindered by a language barrier\n",
        "   Then return ONLY the following JSON:\n",
        "   {\n",
        "     \"status\": \"INSUFFICIENT_DATA\"\n",
        "   }\n",
        "\n",
        "Examples:\n",
        "<examples>\n",
        "1. Complete interaction:\n",
        "<transcript>\n",
        "Agent: Thank you for calling Acme Smart Home Support. This is Alex. How may I assist you today?\n",
        "Customer: Hi Alex, my Acme SmartTherm isn't maintaining the temperature I set. It's set to 72 but the house is much warmer.\n",
        "Agent: I'm sorry to hear that. Let's troubleshoot. Is your SmartTherm connected to Wi-Fi?\n",
        "Customer: Yes, the Wi-Fi symbol is showing on the display.\n",
        "Agent: Great. Let's recalibrate your SmartTherm. Press and hold the menu button for 5 seconds.\n",
        "Customer: Okay, done. A new menu came up.\n",
        "Agent: Perfect. Navigate to \"Calibration\" and press select. Adjust the temperature to match your room thermometer.\n",
        "Customer: Alright, I've set it to 79 degrees to match.\n",
        "Agent: Great. Press select to confirm. It will recalibrate, which may take a few minutes. Check back in an hour to see if it's fixed.\n",
        "Customer: Okay, I'll do that. Thank you for your help, Alex.\n",
        "Agent: You're welcome! Is there anything else I can assist you with today?\n",
        "Customer: No, that's all. Thanks again.\n",
        "Agent: Thank you for choosing Acme Smart Home. Have a great day!\n",
        "</transcript>\n",
        "\n",
        "<thinking>\n",
        "Main issue: SmartTherm not maintaining set temperature\n",
        "Resolution: Guided customer through recalibration process\n",
        "Follow-up: Not required, but customer should check effectiveness after an hour\n",
        "Ambiguities: None identified\n",
        "</thinking>\n",
        "\n",
        "<json>\n",
        "{\n",
        "  \"summary\": {\n",
        "    \"customerIssue\": \"SmartTherm not maintaining set temperature, showing higher than set 72 degrees\",\n",
        "    \"resolution\": \"Guided customer through SmartTherm recalibration process\",\n",
        "    \"followUpRequired\": false,\n",
        "    \"followUpDetails\": null\n",
        "  },\n",
        "  \"status\": \"COMPLETE\",\n",
        "  \"ambiguities\": []\n",
        "}\n",
        "</json>\n",
        "\n",
        "2. Interaction requiring follow-up:\n",
        "<transcript>\n",
        "Agent: Acme Smart Home Support, this is Jamie. How can I help you?\n",
        "Customer: Hi, I just installed my new Acme SmartCam, but I can't get it to connect to my Wi-Fi.\n",
        "Agent: I'd be happy to help. Are you using the Acme Smart Home app?\n",
        "Customer: Yes, I have the app on my phone.\n",
        "Agent: Great. Make sure your phone is connected to the 2.4GHz Wi-Fi network, not the 5GHz one.\n",
        "Customer: Oh, I'm on the 5GHz network. Should I switch?\n",
        "Agent: Yes, please switch to the 2.4GHz network. The SmartCam only works with 2.4GHz.\n",
        "Customer: Okay, done. Now what?\n",
        "Agent: Open the app, select 'Add Device', choose 'SmartCam', and follow the on-screen instructions.\n",
        "Customer: It's asking for a password now.\n",
        "Agent: Enter your Wi-Fi password and it should connect.\n",
        "Customer: It's still not working. I keep getting an error message.\n",
        "Agent: I see. In that case, I'd like to escalate this to our technical team. They'll contact you within 24 hours.\n",
        "Customer: Okay, that sounds good. Thank you for trying to help.\n",
        "Agent: You're welcome. Is there anything else you need assistance with?\n",
        "Customer: No, that's all for now. Thanks again.\n",
        "Agent: Thank you for choosing Acme Smart Home. Have a great day!\n",
        "</transcript>\n",
        "\n",
        "<thinking>\n",
        "Main issue: Customer unable to connect new SmartCam to Wi-Fi\n",
        "Resolution: Initial troubleshooting unsuccessful, issue escalated to technical team\n",
        "Follow-up: Required, technical team to contact customer within 24 hours\n",
        "Ambiguities: Specific error message customer is receiving not mentioned\n",
        "</thinking>\n",
        "\n",
        "<json>\n",
        "{\n",
        "  \"summary\": {\n",
        "    \"customerIssue\": \"Unable to connect new SmartCam to Wi-Fi\",\n",
        "    \"resolution\": \"Initial troubleshooting unsuccessful, issue escalated to technical team\",\n",
        "    \"followUpRequired\": true,\n",
        "    \"followUpDetails\": \"Technical team to contact customer within 24 hours for further assistance\"\n",
        "  },\n",
        "  \"status\": \"COMPLETE\",\n",
        "  \"ambiguities\": [\"Specific error message customer is receiving not mentioned\"]\n",
        "}\n",
        "</json>\n",
        "\n",
        "3. Insufficient data:\n",
        "<transcript>\n",
        "Agent: Acme Smart Home Support, this is Sam. How may I assist you?\n",
        "Customer: Hi, my smart lock isn't working.\n",
        "Agent: I'm sorry to hear that. Can you tell me more about the issue?\n",
        "Customer: It just doesn't work. I don't know what else to say.\n",
        "Agent: Okay, when did you first notice the problem? And what model of Acme smart lock do you have?\n",
        "Customer: I don't remember. Listen, I have to go. I'll call back later.\n",
        "Agent: Alright, we're here 24/7 if you need further assistance. Have a good day.\n",
        "</transcript>\n",
        "\n",
        "<thinking>\n",
        "This transcript has fewer than 5 exchanges and the customer's issue is unclear. The customer doesn't provide specific details about the problem with the smart lock or respond to the agent's questions. This interaction doesn't provide sufficient information for a complete summary.\n",
        "</thinking>\n",
        "\n",
        "<json>\n",
        "{\n",
        "  \"status\": \"INSUFFICIENT_DATA\"\n",
        "}\n",
        "</json>\n",
        "</examples>\n",
        "</instructions>\n",
        "\n",
        "Before generating the JSON, please analyze the transcript in <thinking> tags.\n",
        "Include your identification of the main issue, resolution, follow-up requirements, and any ambiguities.\n",
        "Then, provide your JSON output in <json> tags.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "f2PbumFSGdRi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the role"
      ],
      "metadata": {
        "id": "ZBBkkFcLETSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setting_the_role = \"\"\"\n",
        "You are an AI assistant specialized in analyzing customer reviews.\n",
        "Your task is to determine the overall sentiment of a given review\n",
        "and extract any specific complaints mentioned.\n",
        "Please follow these instructions carefully:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WZw8y5Ie7EFE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make It A Prompt Template"
      ],
      "metadata": {
        "id": "66X1-TUeEjX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llms work better with XMLs\n",
        "\n",
        "instruction_pt1 = \"\"\"\n",
        "1. Review the following customer feedback:\n",
        "\n",
        "<customer_review>\n",
        "{{CUSTOMER_REVIEW}}\n",
        "</customer_review>\n",
        "\"\"\"\n",
        "\n",
        "# <></> to the tell that the start and end of review\n",
        "# {{}} is not a requirement, we can use anything else if we want"
      ],
      "metadata": {
        "id": "Xlu5txQ6EdC2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let the model thing\n",
        "\n",
        "These are the steps which we want our model to go through"
      ],
      "metadata": {
        "id": "C1F8GKqwFNhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_pt2 = \"\"\"\n",
        "2. Analyze the review using the following steps.\n",
        "Show your work in <review_breakdown> tags:\n",
        "\n",
        "a) Key Phrase Extraction:\n",
        "   - Extract and quote key phrases that indicate sentiment\n",
        "   (positive, negative, or neutral).\n",
        "   - Extract and quote key phrases that suggest complaints or issues.\n",
        "\n",
        "b) Sentiment Analysis:\n",
        "   - Consider arguments for positive, negative,\n",
        "   and neutral sentiment based on the extracted phrases.\n",
        "   - Determine the overall sentiment (positive, negative, or neutral)\n",
        "   based on your analysis.\n",
        "   - Explain your reasoning for the sentiment classification.\n",
        "\n",
        "c) Complaint Extraction:\n",
        "   - List each specific issue or problem mentioned in the review.\n",
        "   - For each complaint, provide the relevant quote from the review.\n",
        "   - Count the total number of complaints found.\n",
        "\n",
        "It's OK for this section to be quite long as you\n",
        "thoroughly break down the review.\n",
        "\"\"\"\n",
        "\n",
        "# work will be shown under the review_breakdown tags"
      ],
      "metadata": {
        "id": "j0VMncbkFTi6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output prediction"
      ],
      "metadata": {
        "id": "v-UIsWtJGLD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_pt3 = \"\"\"\n",
        "3. Based on your analysis,\n",
        "generate a JSON output with the following structure:\n",
        "\n",
        "<json>\n",
        "{\n",
        "  \"sentiment_score\": \"Positive|Negative|Neutral\",\n",
        "  \"sentiment_analysis\": \"Explanation of sentiment classification\",\n",
        "  \"complaints\": [\n",
        "    \"Complaint 1\",\n",
        "    \"Complaint 2\",\n",
        "    \"...\"\n",
        "  ]\n",
        "}\n",
        "</json>\n",
        "\n",
        "If no complaints are found,\n",
        "use an empty array for the \"complaints\" field.\n",
        "\n",
        "Remember:\n",
        "- Base your analysis solely on the content of the provided review.\n",
        "- Do not make assumptions or include information\n",
        "not present in the review.\n",
        "- Be objective and focus on the customer's expressed\n",
        "opinions and experiences.\n",
        "- Ensure your JSON output is properly formatted\n",
        "and contains all required fields.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VleK4ce2F68n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assembling the Prompt"
      ],
      "metadata": {
        "id": "iWSfgaBxGqfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = f\"\"\"\n",
        "{setting_the_role}\n",
        "{instruction_pt1}\n",
        "{instruction_pt2}\n",
        "{instruction_pt3}\n",
        "\"\"\"\n",
        "\n",
        "print(final_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TQ-SBy_Gh8o",
        "outputId": "7d0f78db-af7c-49fa-ef83-a18828e56954"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "You are an AI assistant specialized in analyzing customer reviews.\n",
            "Your task is to determine the overall sentiment of a given review\n",
            "and extract any specific complaints mentioned.\n",
            "Please follow these instructions carefully:\n",
            "\n",
            "\n",
            "1. Review the following customer feedback:\n",
            "\n",
            "<customer_review>\n",
            "{{CUSTOMER_REVIEW}}\n",
            "</customer_review>\n",
            "\n",
            "\n",
            "2. Analyze the review using the following steps.\n",
            "Show your work in <review_breakdown> tags:\n",
            "\n",
            "a) Key Phrase Extraction:\n",
            "   - Extract and quote key phrases that indicate sentiment\n",
            "   (positive, negative, or neutral).\n",
            "   - Extract and quote key phrases that suggest complaints or issues.\n",
            "\n",
            "b) Sentiment Analysis:\n",
            "   - Consider arguments for positive, negative,\n",
            "   and neutral sentiment based on the extracted phrases.\n",
            "   - Determine the overall sentiment (positive, negative, or neutral)\n",
            "   based on your analysis.\n",
            "   - Explain your reasoning for the sentiment classification.\n",
            "\n",
            "c) Complaint Extraction:\n",
            "   - List each specific issue or problem mentioned in the review.\n",
            "   - For each complaint, provide the relevant quote from the review.\n",
            "   - Count the total number of complaints found.\n",
            "\n",
            "It's OK for this section to be quite long as you\n",
            "thoroughly break down the review.\n",
            "\n",
            "\n",
            "3. Based on your analysis,\n",
            "generate a JSON output with the following structure:\n",
            "\n",
            "<json>\n",
            "{\n",
            "  \"sentiment_score\": \"Positive|Negative|Neutral\",\n",
            "  \"sentiment_analysis\": \"Explanation of sentiment classification\",\n",
            "  \"complaints\": [\n",
            "    \"Complaint 1\",\n",
            "    \"Complaint 2\",\n",
            "    \"...\"\n",
            "  ]\n",
            "}\n",
            "</json>\n",
            "\n",
            "If no complaints are found,\n",
            "use an empty array for the \"complaints\" field.\n",
            "\n",
            "Remember:\n",
            "- Base your analysis solely on the content of the provided review.\n",
            "- Do not make assumptions or include information\n",
            "not present in the review.\n",
            "- Be objective and focus on the customer's expressed\n",
            "opinions and experiences.\n",
            "- Ensure your JSON output is properly formatted\n",
            "and contains all required fields.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vision_model= \"llama-3.2-90b-vision-preview\"\n",
        "text_model= \"deepseek-r1-distill-llama-70b\""
      ],
      "metadata": {
        "id": "fTMMxQb6Hdoa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_review_sentiment(review):\n",
        "    #Insert the context into the prompt\n",
        "    prompt = final_prompt.replace(\"{{CUSTOMER_REVIEW}}\", review)\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=text_model,\n",
        "    )\n",
        "    output= chat_completion.choices[0].message.content\n",
        "    print(\"ENTIRE MODEL OUTPUT: \")\n",
        "    print(output)\n",
        "\n",
        "    sentiment = re.search(r'<json>(.*?)</json>', output, re.DOTALL)\n",
        "\n",
        "    if sentiment:\n",
        "        print(\"FINAL JSON OUTPUT: \")\n",
        "        print(sentiment.group(1).strip())\n",
        "    else:\n",
        "        print(\"No sentiment analysis in the response.\")"
      ],
      "metadata": {
        "id": "tD6Ehft_Gtrb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing the model"
      ],
      "metadata": {
        "id": "LNCenu4bPtRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review1 = \"\"\"\n",
        "I am in love with my Acme phone.  It's incredible.\n",
        "It's a little expensive, but so worth it imo.\n",
        "If you can afford it, it's worth it!\n",
        "I love the colors too!\n",
        "\"\"\"\n",
        "\n",
        "get_review_sentiment(review1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSA3VWFvISog",
        "outputId": "4d2b5420-a615-40c8-ac23-b5a3e2daec0b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENTIRE MODEL OUTPUT: \n",
            "<think>\n",
            "Okay, so I need to analyze this customer review. Let me start by reading it carefully.\n",
            "\n",
            "The review says, \"I am in love with my Acme phone. It's incredible. It's a little expensive, but so worth it imo. If you can afford it, it's worth it! I love the colors too!\"\n",
            "\n",
            "First, I'll extract key phrases that indicate sentiment. The positive phrases are \"I am in love with my Acme phone,\" \"It's incredible,\" \"so worth it imo,\" \"worth it,\" and \"I love the colors too!\" The only negative phrase is \"It's a little expensive.\"\n",
            "\n",
            "Now, for sentiment analysis. The customer uses strong positive language like \"in love\" and \"incredible,\" which shows enthusiasm. They mention the price being high but quickly justify it by saying it's worth it. This suggests that the positive aspects outweigh the negative. So overall, the sentiment is positive.\n",
            "\n",
            "Next, extracting complaints. The only issue mentioned is the expense, as indicated by \"It's a little expensive.\" There are no other problems noted.\n",
            "\n",
            "So, the JSON output should reflect a positive sentiment with one complaint about the price.\n",
            "</think>\n",
            "\n",
            "<review_breakdown>\n",
            "a) Key Phrase Extraction:\n",
            "   - Positive sentiment phrases:\n",
            "     - \"I am in love with my Acme phone\"\n",
            "     - \"It's incredible\"\n",
            "     - \"so worth it imo\"\n",
            "     - \"If you can afford it, it's worth it\"\n",
            "     - \"I love the colors too!\"\n",
            "   - Complaints or issues:\n",
            "     - \"It's a little expensive\"\n",
            "\n",
            "b) Sentiment Analysis:\n",
            "   - Arguments for positive sentiment:\n",
            "     - The customer expresses strong affection for the product (\"I am in love with my Acme phone\").\n",
            "     - The customer uses superlatives to describe the product (\"It's incredible\").\n",
            "     - The customer justifies the cost (\"so worth it imo\", \"If you can afford it, it's worth it\").\n",
            "     - The customer praises specific features (\"I love the colors too!\").\n",
            "   - Arguments for negative sentiment:\n",
            "     - The customer mentions that the product is expensive (\"It's a little expensive\").\n",
            "   - Overall sentiment: Positive\n",
            "   - Reasoning: While the customer mentions the product being expensive, they quickly justify it by stating it's worth the cost. The overwhelming tone of the review is positive, with the customer expressing love and enthusiasm for the product.\n",
            "\n",
            "c) Complaint Extraction:\n",
            "   - Specific issues or problems mentioned:\n",
            "     1. \"It's a little expensive\" - The customer mentions the product is expensive, though they justify it by saying it's worth the cost.\n",
            "   - Total number of complaints: 1\n",
            "</review_breakdown>\n",
            "\n",
            "<json>\n",
            "{\n",
            "  \"sentiment_score\": \"Positive\",\n",
            "  \"sentiment_analysis\": \"The customer expresses strong positive sentiment towards the Acme phone, using phrases like 'I am in love' and 'It's incredible.' While they mention the product is 'a little expensive,' they justify the cost by stating it's worth it. The overall tone is enthusiastic and positive.\",\n",
            "  \"complaints\": [\n",
            "    \"It's a little expensive\"\n",
            "  ]\n",
            "}\n",
            "</json>\n",
            "FINAL JSON OUTPUT: \n",
            "{\n",
            "  \"sentiment_score\": \"Positive\",\n",
            "  \"sentiment_analysis\": \"The customer expresses strong positive sentiment towards the Acme phone, using phrases like 'I am in love' and 'It's incredible.' While they mention the product is 'a little expensive,' they justify the cost by stating it's worth it. The overall tone is enthusiastic and positive.\",\n",
            "  \"complaints\": [\n",
            "    \"It's a little expensive\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review2 = \"\"\"\n",
        "I recently bought the ABC Smartwatch, and I have to say, it's been a\n",
        "bit of a rollercoaster. Let's start with the good stuff -\n",
        "the design is absolutely gorgeous. It's sleek, lightweight,\n",
        "and looks fantastic on my wrist. The display is crisp and bright,\n",
        "even in direct sunlight. I also love how customizable the watch\n",
        "faces are, allowing me to switch up the look whenever I want.\n",
        "However, there are some significant downsides that I can't ignore.\n",
        "The battery life is terrible - I'm lucky if I get through a full\n",
        "day without needing to charge it. This is especially frustrating\n",
        "when I'm traveling or out for long periods. The fitness tracking\n",
        "features, which were a big selling point for me, are hit or miss.\n",
        "It often doesn't accurately count my steps or calculate calories burned\n",
        "during workouts. Another issue I've encountered is with the touch\n",
        "sensitivity. Sometimes it's overly sensitive, registering accidental\n",
        "touches, while other times I have to tap multiple times for it to\n",
        "respond. It's inconsistent and annoying, especially when I'm trying to\n",
        "quickly check notifications or start a workout.On the plus side, the\n",
        "integration with my smartphone is seamless, and I appreciate being able\n",
        "to respond to texts and calls from my wrist. The water resistance has\n",
        "also held up well - I've worn it while swimming without any problems.\n",
        "Customer service has been decent. They were quick to respond when I\n",
        "reported the battery issue, but their solution of turning off certain\n",
        "features defeats the purpose of having a smartwatch. All in all, while\n",
        "there are aspects of the ABC Smartwatch that I really like, the battery\n",
        "life and inconsistent performance are major drawbacks. For the price\n",
        "point, I expected better. It's not worth your money.\n",
        "\"\"\"\n",
        "\n",
        "get_review_sentiment(review2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdmrpAYqPlFn",
        "outputId": "c3035fff-4f83-40cf-a48e-30630bcf4851"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENTIRE MODEL OUTPUT: \n",
            "<think>\n",
            "Okay, I need to analyze this customer review of the ABC Smartwatch. Let me start by reading through the review carefully to understand the customer's experience.\n",
            "\n",
            "The customer begins by mentioning that their experience has been a \"rollercoaster,\" which suggests there are both positive and negative aspects. They start with the positives: the design is \"absolutely gorgeous,\" \"sleek, lightweight,\" and the display is \"crisp and bright.\" They also appreciate the customizable watch faces. These are all positive points.\n",
            "\n",
            "Then, the customer shifts to the negatives. They mention \"significant downsides.\" The first issue is the battery life, which they describe as \"terrible,\" only lasting a full day. This is especially frustrating during travel or long periods. Next, they talk about the fitness tracking features being \"hit or miss,\" with inaccurate step counts and calorie calculations. Another problem is the touch sensitivity, which is either too sensitive or unresponsive, causing accidental touches and requiring multiple taps. They also express frustration with the customer service solution, which they feel defeats the purpose of having a smartwatch.\n",
            "\n",
            "On the positive side again, they mention seamless smartphone integration, water resistance holding up well, and decent customer service, though the solution wasn't satisfactory.\n",
            "\n",
            "Overall, the customer concludes that while they like some aspects, the battery life and performance issues are major drawbacks, making the product not worth the price.\n",
            "\n",
            "Now, for the key phrase extraction, I'll note both positive and negative sentiments. Positive phrases include \"absolutely gorgeous,\" \"sleek, lightweight,\" \"crisp and bright,\" and \"seamless integration.\" Negative phrases include \"battery life is terrible,\" \"fitness tracking features... hit or miss,\" \"inconsistent and annoying,\" and \"not worth your money.\"\n",
            "\n",
            "For sentiment analysis, there are both positive and negative points, but the negative issues seem to have a bigger impact. The customer is disappointed with the product's performance and value, leading me to classify the overall sentiment as negative.\n",
            "\n",
            "Extracting complaints, I list each specific issue: poor battery life, inaccurate fitness tracking, inconsistent touch sensitivity, and unsatisfactory customer service solution. That's four complaints in total.\n",
            "\n",
            "Finally, I'll structure the JSON output with the sentiment as negative, provide an explanation, and list the complaints.\n",
            "</think>\n",
            "\n",
            "<review_breakdown>\n",
            "a) Key Phrase Extraction:\n",
            "- Positive: \"absolutely gorgeous\", \"sleek, lightweight\", \"crisp and bright\", \"seamless integration\", \"water resistance has held up well\", \"customer service has been decent\".\n",
            "- Negative: \"battery life is terrible\", \"fitness tracking features... hit or miss\", \"inconsistent and annoying\", \"not worth your money\".\n",
            "\n",
            "b) Sentiment Analysis:\n",
            "- Positive aspects: Design, display, customization, integration, water resistance, customer service.\n",
            "- Negative aspects: Battery life, fitness tracking, touch sensitivity, customer service solution.\n",
            "- Overall sentiment: Negative. The significant issues with battery life and performance outweigh the positives, leading to disappointment and a conclusion that the product isn't worth the price.\n",
            "\n",
            "c) Complaint Extraction:\n",
            "1. \"battery life is terrible\"\n",
            "2. \"fitness tracking features... hit or miss\"\n",
            "3. \"inconsistent and annoying\" (touch sensitivity)\n",
            "4. \"their solution... defeats the purpose\" (customer service)\n",
            "</review_breakdown>\n",
            "\n",
            "<json>\n",
            "{\n",
            "  \"sentiment_score\": \"Negative\",\n",
            "  \"sentiment_analysis\": \"The review highlights significant negative issues with battery life, fitness tracking, and touch sensitivity, which overshadow the positive aspects. The customer feels the product isn't worth the price, leading to an overall negative sentiment.\",\n",
            "  \"complaints\": [\n",
            "    \"battery life is terrible\",\n",
            "    \"fitness tracking features are hit or miss\",\n",
            "    \"touch sensitivity is inconsistent and annoying\",\n",
            "    \"customer service solution defeats the purpose\"\n",
            "  ]\n",
            "}\n",
            "</json>\n",
            "FINAL JSON OUTPUT: \n",
            "{\n",
            "  \"sentiment_score\": \"Negative\",\n",
            "  \"sentiment_analysis\": \"The review highlights significant negative issues with battery life, fitness tracking, and touch sensitivity, which overshadow the positive aspects. The customer feels the product isn't worth the price, leading to an overall negative sentiment.\",\n",
            "  \"complaints\": [\n",
            "    \"battery life is terrible\",\n",
            "    \"fitness tracking features are hit or miss\",\n",
            "    \"touch sensitivity is inconsistent and annoying\",\n",
            "    \"customer service solution defeats the purpose\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N shot prompting\n",
        "\n",
        "When the model is not performing well then we give example to show model how to work"
      ],
      "metadata": {
        "id": "nczKnczzQTy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = \"\"\"\n",
        "Here are some example inputs and outputs to help you understand\n",
        "the sort of analysis we're looking for\n",
        "<examples>\n",
        "<example1>\n",
        "\n",
        "<customer_review>\n",
        "I recently bought the ABC Smartwatch, and I have to say, it's been a bit of a rollercoaster. Let's start with the good stuff - the design is absolutely gorgeous. It's sleek, lightweight, and looks fantastic on my wrist. The display is crisp and bright, even in direct sunlight. I also love how customizable the watch faces are, allowing me to switch up the look whenever I want.\n",
        "However, there are some significant downsides that I can't ignore. The battery life is terrible - I'm lucky if I get through a full day without needing to charge it. This is especially frustrating when I'm traveling or out for long periods. The fitness tracking features, which were a big selling point for me, are hit or miss. It often doesn't accurately count my steps or calculate calories burned during workouts.\n",
        "Another issue I've encountered is with the touch sensitivity. Sometimes it's overly sensitive, registering accidental touches, while other times I have to tap multiple times for it to respond. It's inconsistent and annoying, especially when I'm trying to quickly check notifications or start a workout.\n",
        "On the plus side, the integration with my smartphone is seamless, and I appreciate being able to respond to texts and calls from my wrist. The water resistance has also held up well - I've worn it while swimming without any problems.\n",
        "Customer service has been decent. They were quick to respond when I reported the battery issue, but their solution of turning off certain features defeats the purpose of having a smartwatch.\n",
        "All in all, while there are aspects of the ABC Smartwatch that I really like, the battery life and inconsistent performance are major drawbacks. For the price point, I expected better. It's not worth your money.\n",
        "</customer_review>\n",
        "\n",
        "<ideal_output>\n",
        "<review_analysis>\n",
        "a) Key Phrase Extraction:\n",
        "\n",
        "Positive Phrases:\n",
        "1. \"design is absolutely gorgeous\"\n",
        "2. \"sleek, lightweight, and looks fantastic\"\n",
        "3. \"display is crisp and bright\"\n",
        "4. \"love how customizable the watch faces are\"\n",
        "5. \"integration with my smartphone is seamless\"\n",
        "6. \"water resistance has held up well\"\n",
        "7. \"customer service has been decent\"\n",
        "\n",
        "Negative Phrases:\n",
        "1. \"bit of a rollercoaster\"\n",
        "2. \"battery life is terrible\"\n",
        "3. \"lucky if I get through a full day\"\n",
        "4. \"fitness tracking features are hit or miss\"\n",
        "5. \"doesn't accurately count my steps\"\n",
        "6. \"touch sensitivity... overly sensitive\"\n",
        "7. \"have to tap multiple times\"\n",
        "8. \"inconsistent and annoying\"\n",
        "9. \"solution of turning off certain features defeats the purpose\"\n",
        "10. \"battery life and inconsistent performance are major drawbacks\"\n",
        "11. \"not worth your money\"\n",
        "\n",
        "b) Sentiment Analysis:\n",
        "Arguments for positive sentiment:\n",
        "- The design and aesthetics of the watch are highly praised\n",
        "- The display quality is commended\n",
        "- Customization options are appreciated\n",
        "- Smartphone integration works well\n",
        "- Water resistance feature is effective\n",
        "- Customer service responded quickly\n",
        "\n",
        "Arguments for negative sentiment:\n",
        "- Battery life is severely criticized\n",
        "- Fitness tracking, a key feature, is unreliable\n",
        "- Touch sensitivity issues cause frustration\n",
        "- The proposed solution compromises functionality\n",
        "- The price doesn't justify the performance\n",
        "- The reviewer explicitly states it's not worth the money\n",
        "\n",
        "Considering the strength and frequency of sentiments:\n",
        "- Positive sentiments are mostly about aesthetics and basic functions\n",
        "- Negative sentiments relate to core functionalities and user experience\n",
        "- The reviewer uses stronger language for negative aspects (\"terrible\", \"major drawbacks\", \"not worth your money\")\n",
        "- The conclusion emphasizes disappointment and recommends against purchase\n",
        "\n",
        "Based on this analysis, the overall sentiment leans negative. While the reviewer appreciates certain aspects, the core issues with battery life, performance, and value for money overshadow the positives. The explicit recommendation against purchase is a strong indicator of overall negative sentiment.\n",
        "\n",
        "c) Complaint Extraction:\n",
        "1. Poor battery life\n",
        "   Quote: \"The battery life is terrible - I'm lucky if I get through a full day without needing to charge it\"\n",
        "\n",
        "2. Inaccurate fitness tracking\n",
        "   Quote: \"The fitness tracking features, which were a big selling point for me, are hit or miss. It often doesn't accurately count my steps or calculate calories burned during workouts\"\n",
        "\n",
        "3. Inconsistent touch sensitivity\n",
        "   Quote: \"Sometimes it's overly sensitive, registering accidental touches, while other times I have to tap multiple times for it to respond\"\n",
        "\n",
        "4. Inadequate solution to problems\n",
        "   Quote: \"their solution of turning off certain features defeats the purpose of having a smartwatch\"\n",
        "\n",
        "Total Complaints: 4\n",
        "\n",
        "d) Summary:\n",
        "The analysis of the ABC Smartwatch review reveals a predominantly negative sentiment. While the customer appreciates the design, display quality, and some basic features, these positives are outweighed by significant issues with core functionalities. The main complaints center around poor battery life, inaccurate fitness tracking, inconsistent touch sensitivity, and inadequate problem-solving from customer service. The reviewer concludes that the product is not worth the money, emphasizing that the drawbacks are too significant to justify the price point.\n",
        "</review_analysis>\n",
        "\n",
        "<json>\n",
        "{\n",
        "  \"sentiment_score\": \"Negative\",\n",
        "  \"sentiment_analysis\": \"While the review acknowledges positive aspects like design and basic functionality, the overall sentiment is negative due to significant issues with core features (battery life, fitness tracking, touch sensitivity). The reviewer explicitly states it's 'not worth your money' and emphasizes major drawbacks that overshadow the positive elements.\",\n",
        "  \"complaints\": [\n",
        "    \"Poor battery life requiring daily charging\",\n",
        "    \"Inaccurate fitness tracking features\",\n",
        "    \"Inconsistent touch sensitivity causing user interface problems\",\n",
        "    \"Inadequate customer service solutions that compromise device functionality\"\n",
        "  ]\n",
        "}\n",
        "</json>\n",
        "</ideal_output>\n",
        "\n",
        "</example1>\n",
        "</examples>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "I7hKnLOHP2qP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the Text"
      ],
      "metadata": {
        "id": "Z-DLPJEkWRDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('frankenstein.txt', 'r') as file:\n",
        "    book_content = file.read()\n",
        "\n",
        "len(book_content)\n",
        "\n",
        "book_content[1000:2000]"
      ],
      "metadata": {
        "id": "eRjJPjvOQd2K"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def make_non_cached_api_call():\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"<book>\" + book_content + \"</book>\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"What happens in chapter 3?\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        max_tokens=500,\n",
        "        messages=messages,\n",
        "    )\n",
        "    end_time = time.time()\n",
        "\n",
        "    return response, end_time - start_time"
      ],
      "metadata": {
        "id": "hts74dDIWSv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_cached_response, non_cached_time = make_non_cached_api_call()\n",
        "print(f\"Non-cached time: {non_cached_time:.2f} seconds\")\n",
        "\n",
        "print(\"\\nOutput (non-cached):\")\n",
        "print(non_cached_response.content)\n",
        "\n",
        "## Not possible with free models, max allowed tokens are around 6000-10000"
      ],
      "metadata": {
        "id": "6mfFUH_rXGWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_cached_api_call():\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"<book>\" + book_content + \"</book>\",\n",
        "                    \"cache_control\": {\"type\": \"ephemeral\"}\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"What happens in chapter 5?\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()\n",
        "    response = client.chat.completions.create(\n",
        "        model=text_model,\n",
        "        max_tokens=500,\n",
        "        messages=messages,\n",
        "    )\n",
        "    end_time = time.time()\n",
        "\n",
        "    return response, end_time - start_time"
      ],
      "metadata": {
        "id": "WZsMFtMzXIlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1, duration1 = make_cached_api_call()\n",
        "response1"
      ],
      "metadata": {
        "id": "nfP5bjUFYSfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2, duration2 = make_cached_api_call()\n",
        "response2.usage ,duration2"
      ],
      "metadata": {
        "id": "NDQg53bCYWub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with tools"
      ],
      "metadata": {
        "id": "Vs7mAz2eEmG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeDatabase:\n",
        "    def __init__(self):\n",
        "        self.customers = [\n",
        "            {\"id\": \"1213210\", \"name\": \"John Doe\", \"email\": \"john@gmail.com\", \"phone\": \"123-456-7890\", \"username\": \"johndoe\"},\n",
        "            {\"id\": \"2837622\", \"name\": \"Priya Patel\", \"email\": \"priya@candy.com\", \"phone\": \"987-654-3210\", \"username\": \"priya123\"},\n",
        "            {\"id\": \"3924156\", \"name\": \"Liam Nguyen\", \"email\": \"lnguyen@yahoo.com\", \"phone\": \"555-123-4567\", \"username\": \"liamn\"},\n",
        "            {\"id\": \"4782901\", \"name\": \"Aaliyah Davis\", \"email\": \"aaliyahd@hotmail.com\", \"phone\": \"111-222-3333\", \"username\": \"adavis\"},\n",
        "            {\"id\": \"5190753\", \"name\": \"Hiroshi Nakamura\", \"email\": \"hiroshi@gmail.com\", \"phone\": \"444-555-6666\", \"username\": \"hiroshin\"},\n",
        "            {\"id\": \"6824095\", \"name\": \"Fatima Ahmed\", \"email\": \"fatimaa@outlook.com\", \"phone\": \"777-888-9999\", \"username\": \"fatimaahmed\"},\n",
        "            {\"id\": \"7135680\", \"name\": \"Alejandro Rodriguez\", \"email\": \"arodriguez@protonmail.com\", \"phone\": \"222-333-4444\", \"username\": \"alexr\"},\n",
        "            {\"id\": \"8259147\", \"name\": \"Megan Anderson\", \"email\": \"megana@gmail.com\", \"phone\": \"666-777-8888\", \"username\": \"manderson\"},\n",
        "            {\"id\": \"9603481\", \"name\": \"Kwame Osei\", \"email\": \"kwameo@yahoo.com\", \"phone\": \"999-000-1111\", \"username\": \"kwameo\"},\n",
        "            {\"id\": \"1057426\", \"name\": \"Mei Lin\", \"email\": \"meilin@gmail.com\", \"phone\": \"333-444-5555\", \"username\": \"mlin\"}\n",
        "        ]\n",
        "\n",
        "        self.orders = [\n",
        "            {\"id\": \"24601\", \"customer_id\": \"1213210\", \"product\": \"Wireless Headphones\", \"quantity\": 1, \"price\": 79.99, \"status\": \"Shipped\"},\n",
        "            {\"id\": \"13579\", \"customer_id\": \"1213210\", \"product\": \"Smartphone Case\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Processing\"},\n",
        "            {\"id\": \"97531\", \"customer_id\": \"2837622\", \"product\": \"Bluetooth Speaker\", \"quantity\": 1, \"price\": \"49.99\", \"status\": \"Shipped\"},\n",
        "            {\"id\": \"86420\", \"customer_id\": \"3924156\", \"product\": \"Fitness Tracker\", \"quantity\": 1, \"price\": 129.99, \"status\": \"Delivered\"},\n",
        "            {\"id\": \"54321\", \"customer_id\": \"4782901\", \"product\": \"Laptop Sleeve\", \"quantity\": 3, \"price\": 24.99, \"status\": \"Shipped\"},\n",
        "            {\"id\": \"19283\", \"customer_id\": \"5190753\", \"product\": \"Wireless Mouse\", \"quantity\": 1, \"price\": 34.99, \"status\": \"Processing\"},\n",
        "            {\"id\": \"74651\", \"customer_id\": \"6824095\", \"product\": \"Gaming Keyboard\", \"quantity\": 1, \"price\": 89.99, \"status\": \"Delivered\"},\n",
        "            {\"id\": \"30298\", \"customer_id\": \"7135680\", \"product\": \"Portable Charger\", \"quantity\": 2, \"price\": 29.99, \"status\": \"Shipped\"},\n",
        "            {\"id\": \"47652\", \"customer_id\": \"8259147\", \"product\": \"Smartwatch\", \"quantity\": 1, \"price\": 199.99, \"status\": \"Processing\"},\n",
        "            {\"id\": \"61984\", \"customer_id\": \"9603481\", \"product\": \"Noise-Cancelling Headphones\", \"quantity\": 1, \"price\": 149.99, \"status\": \"Shipped\"},\n",
        "            {\"id\": \"58243\", \"customer_id\": \"1057426\", \"product\": \"Wireless Earbuds\", \"quantity\": 2, \"price\": 99.99, \"status\": \"Delivered\"},\n",
        "            {\"id\": \"90357\", \"customer_id\": \"1213210\", \"product\": \"Smartphone Case\", \"quantity\": 1, \"price\": 19.99, \"status\": \"Shipped\"},\n",
        "            {\"id\": \"28164\", \"customer_id\": \"2837622\", \"product\": \"Wireless Headphones\", \"quantity\": 2, \"price\": 79.99, \"status\": \"Processing\"}\n",
        "        ]\n",
        "\n",
        "    def get_user(self, key, value):\n",
        "        if key in {\"email\", \"phone\", \"username\"}:\n",
        "            for customer in self.customers:\n",
        "                if customer[key] == value:\n",
        "                    return customer\n",
        "            return f\"Couldn't find a user with {key} of {value}\"\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid key: {key}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "    def get_order_by_id(self, order_id):\n",
        "        for order in self.orders:\n",
        "            if order[\"id\"] == order_id:\n",
        "                return order\n",
        "        return None\n",
        "\n",
        "    def get_customer_orders(self, customer_id):\n",
        "        return [order for order in self.orders if order[\"customer_id\"] == customer_id]\n",
        "\n",
        "    def cancel_order(self, order_id):\n",
        "        order = self.get_order_by_id(order_id)\n",
        "        if order:\n",
        "            if order[\"status\"] == \"Processing\":\n",
        "                order[\"status\"] = \"Cancelled\"\n",
        "                return \"Cancelled the order\"\n",
        "            else:\n",
        "                return \"Order has already shipped.  Can't cancel it.\"\n",
        "        return \"Can't find that order!\""
      ],
      "metadata": {
        "id": "ir3bLAHaEj3k"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2XvR_WLnEp1o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}